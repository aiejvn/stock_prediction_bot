{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yahoo Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\noten\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\noten\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\noten\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\noten\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\noten\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.0.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\noten\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\noten\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: requests in c:\\users\\noten\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\noten\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\noten\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\noten\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\noten\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4\n",
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.investing.com/equities/amazon-com-inc\"\n",
    "page = requests.get(url)\n",
    "\n",
    "print(page.status_code) # 200 means successful request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful CSS class tags for webscraping\n",
    "\n",
    "h1_class = \"mb-2.5 text-left text-xl font-bold leading-7 text-[#232526] md:mb-2 md:text-3xl md:leading-8 rtl:soft-ltr\"\n",
    "price_class = \"text-5xl/9 font-bold text-[#232526] md:text-[42px] md:leading-[60px]\"\n",
    "price_change_class = \"instrument-price-change\"\n",
    "percent_change_class = \"instrument-price-change-percent\"\n",
    "\n",
    "change_classes = [\"flex items-center gap-2 text-base/6 font-bold md:text-xl/7 rtl:force-ltr text-negative-main\", \n",
    "                  \"flex items-center gap-2 text-base/6 font-bold md:text-xl/7 rtl:force-ltr text-positive-main\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Beautiful Soup returns a parsed tree, so we can now navigate the tree and pick the element we want, even though we don't have the exact CSS class.\n",
    "What we do here is go up in the heirarchy and find a parent div we can exploit. Then, we can use find_all('span') to make a list of all the elements\n",
    "containing the span tag - which we know our target data uses. And because it's a list, we can now easily navigate it and pick those we need.  \n",
    "\n",
    "soup.find(html tag, class = ...) returns the first occurence of a class matching the specified one with the matching html tag.\n",
    "\"\"\"\n",
    "\n",
    "company = soup.find('h1', {'class': h1_class}).text\n",
    "price = soup.find('div', {'class': price_class}).text\n",
    "\n",
    "loss_test = soup.find('div', {'class': change_classes[0]})\n",
    "if loss_test == None:\n",
    "    price_change = soup.find('div', {'class': change_classes[1]}).find_all('span')[0].text\n",
    "    percent_change = soup.find('div', {'class': change_classes[1]}).find_all('span')[1].text[1:-2] # remove unnecessary brackets and percent    \n",
    "else:    \n",
    "    price_change = loss_test.find_all('span')[0].text\n",
    "    percent_change = loss_test.find_all('span')[1].text[1:-2] # remove unnecessary brackets and percent\n",
    "\n",
    "# print(soup.find('div', {'class': change_class}).find_all('span')[1].text[1:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading https://www.investing.com/equities/amazon-com-inc\n",
      "Amazon.com Inc (AMZN) 179.62 +5.95 +3.43\n"
     ]
    }
   ],
   "source": [
    "# test run:\n",
    "print('Loading ' + url)\n",
    "print(company, price, price_change, percent_change) # only gets one value - can we get more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# # https://www.investing.com/equities/amazon-com-inc-historical-data - fill in data from then (1/1/2018) to now (whatever today is)\n",
    "\n",
    "period_url = \"https://www.investing.com/equities/amazon-com-inc-historical-data\"\n",
    "period_page = requests.get(period_url)\n",
    "print(period_page.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['04/26/2024', '04/25/2024', '04/24/2024', '04/23/2024', '04/22/2024', '04/19/2024', '04/18/2024', '04/17/2024', '04/16/2024', '04/15/2024', '04/12/2024', '04/11/2024', '04/10/2024', '04/09/2024', '04/08/2024', '04/05/2024', '04/04/2024', '04/03/2024', '04/02/2024', '04/01/2024', '03/28/2024', '03/27/2024', '03/26/2024']\n",
      "['178.86', '173.66', '176.59', '179.55', '177.23', '174.63', '179.22', '181.28', '183.32', '183.62', '186.13', '189.05', '185.95', '185.67', '185.19', '185.07', '180.00', '182.41', '180.69', '180.97', '180.38', '179.83', '178.30']\n",
      "['+2.99', '-1.66', '-1.65', '+1.31', '+1.49', '-2.56', '-1.14', '-1.11', '-0.16', '-1.35', '-1.54', '+1.67', '+0.15', '+0.26', '+0.06', '+2.82', '-1.32', '+0.95', '-0.15', '+0.33', '+0.31', '+0.86', '-0.78']\n"
     ]
    }
   ],
   "source": [
    "period_soup = BeautifulSoup(period_page.text, 'html.parser')\n",
    "all_date_class = \"freeze-column-w-1 w-full overflow-x-auto text-xs leading-4\"\n",
    "# test_class = \"relative h-[41px] after:absolute after:bottom-0 after:left-0 after:right-0 after:h-px after:bg-[#ECEDEF] hover:bg-[#F5F5F5] historical-data-v2_price__atUfP\"\n",
    "table = period_soup.find('table', {'class': all_date_class})\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "i = 0\n",
    "dates = []\n",
    "prices = []\n",
    "changes = []\n",
    "for row in rows:\n",
    "    # cells = row.find_all(['th', 'td'])\n",
    "    cells = row.find_all('td')\n",
    "    for cell in cells:\n",
    "        match i:\n",
    "            case 0:\n",
    "                dates.append(cell.text)\n",
    "            case 1:\n",
    "                prices.append(cell.text)\n",
    "            case 6:\n",
    "                changes.append(cell.text[:-1])\n",
    "        i += 1\n",
    "        # print(i)\n",
    "        if i > 6:\n",
    "            i = 0\n",
    "print(dates)\n",
    "print(prices)\n",
    "print(changes)            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
